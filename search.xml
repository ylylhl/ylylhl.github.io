<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/03/28/hello-world/"/>
      <url>/2019/03/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>C4.5的python实现</title>
      <link href="/2018/03/29/%E4%BB%93%E5%BA%93%EF%BC%9AC4-5%E7%9A%84python%E5%AE%9E%E7%8E%B0/"/>
      <url>/2018/03/29/%E4%BB%93%E5%BA%93%EF%BC%9AC4-5%E7%9A%84python%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p>尝试着写了一下，只是在重复造轮子而已<excerpt in index | 首页摘要><br><a id="more"></a></excerpt></p><p><the rest of contents | 余下全文><br>开始后的第三周，尝试着写了一点。<br>edit：于4月8日增加连续值处理，具体参见<a href="https://www.jianshu.com/p/f7219841916a" target="_blank" rel="noopener">https://www.jianshu.com/p/f7219841916a</a><br>edit：4月10日消减部分代码量<br>数据集如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">OUTLOOK TEMPERATURE HUMIDITY WINDY ACTIVATE</span><br><span class="line">sunny 85 85 weak no</span><br><span class="line">sunny 80 90 strong no</span><br><span class="line">overcast 83 78 weak yes</span><br><span class="line">rainy 70 96 weak yes</span><br><span class="line">rainy 68 80 weak yes</span><br><span class="line">rainy 65 70 strong no</span><br><span class="line">overcast 64 65 strong yes</span><br><span class="line">sunny 72 95 weak no</span><br><span class="line">sunny 69 70 weak yes</span><br><span class="line">rainy 75 80 weak yes</span><br><span class="line">sunny 75 70 strong yes</span><br><span class="line">overcast 72 90 strong yes</span><br><span class="line">overcast 81 75 weak yes</span><br><span class="line">rainy 71 80 strong no</span><br></pre></td></tr></table></figure></the></p><p>思路很迷，如果有谁不幸看到了这篇请不要当做参考会被带到沟里的……<br>有1点问题，关于max默认取第一个值……比如两个属性的信息增益率相等且都最大，取不同的属性作为节点会生成不同的树（。<br>所以该怎么办哦www</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">#coding = utf-8</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">●C4.5 v1.1</span><br><span class="line">作者：Kadoya</span><br><span class="line">创建日期：18.3.24</span><br><span class="line">最近修改时间：18.4.10</span><br><span class="line">程序目的：一个树:D</span><br><span class="line">主要算法说明：</span><br><span class="line">        1.说白了（大概）就是权重排序，或者看下面这一堆废话也行。</span><br><span class="line">            读取文档→拿到属性→调stardust()拿到具体数据（列表）→</span><br><span class="line">            调continuous()处理连续值→调entropy()拿到结果熵（playgolf?）→</span><br><span class="line">            将数据集，属性和结果熵传入gotcha()，即用于找到下一个节点和子集的函数</span><br><span class="line">            ①如果结果是纯的或满足某种条件则return（对应书上第2~4行）</span><br><span class="line">            ②调gainratio()得到每个属性对应的信息增益率并排序，取最大的作为节点</span><br><span class="line">            ③生成基于该属性不同取值的不同子集，计算子集的结果熵并再次调用gotcha()（第11~14行）</span><br><span class="line">            返回tree并输出（第15行）</span><br><span class="line">        2.凑不齐三点了不管了x</span><br><span class="line">程序备注：</span><br><span class="line">        1.蜃楼啥时候上steam啊……</span><br><span class="line">        2.教授！！！来我迦了！！！毒针地狱.jpg 为了刷毒针正式移民乌鲁克……</span><br><span class="line">        3.一人血书医生早日实装（</span><br><span class="line">更新历史：</span><br><span class="line">        3.28 v1.0</span><br><span class="line">            ①基本功能完成，小bug不计其数，智障操作不计其数</span><br><span class="line">        4.8 update v1.05</span><br><span class="line">            ①增加连续值处理</span><br><span class="line">            ②可以引random达到增益率相同时的选择伪随机而非直接[0]选择第一个但是没改</span><br><span class="line">        4.10 update v1.1</span><br><span class="line">            ①连续值那里原本的int改了float，免得有小数</span><br><span class="line">            ②精简部分代码，纯代码部分压缩到80行</span><br><span class="line"></span><br><span class="line">说实话上次好像说了有个bug要改，想不起来了（……</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">from math import *</span><br><span class="line"></span><br><span class="line">def stardust(data):#具体数据,参数：读到的源文档</span><br><span class="line">    attributes=[]#属性:outlook,temperature,humidity,windy之类</span><br><span class="line">    for i in data[0].split(&apos; &apos;)[0:-1]:#最后一列是结果(play golf?)所以不算</span><br><span class="line">        attributes.append(i)          #拿到所有属性</span><br><span class="line">    lost_star=[]</span><br><span class="line">    for i in data[1:]:#第一行是说明所以不算，下一个.jpg</span><br><span class="line">        lost_star.append(i.strip(&apos;\n&apos;).split(&apos; &apos;)[0:])#删除换行符，以空格分割</span><br><span class="line">    lost_star=continuous(lost_star,1)</span><br><span class="line">    lost_star=continuous(lost_star,2)</span><br><span class="line">    en = entropy(lost_star,len(lost_star[0])-1)</span><br><span class="line">    return attributes,lost_star,en</span><br><span class="line"></span><br><span class="line">def get_subset(lost_star,value,j):#生成子集 参数：数据集，属性具体取值,所在列数</span><br><span class="line">    subset=[lost_star[i] for i in range(len(lost_star)) if lost_star[i][j]==value]</span><br><span class="line">    return subset</span><br><span class="line"></span><br><span class="line">def continuous(lost_star,l):#连续值的阈值 参数：数据集，连续值所在列数</span><br><span class="line">    #不转float会出现15,7,89这种情况，大概是因为str先比第一位，大概。</span><br><span class="line">    gear=sorted(lost_star,key=lambda st: float(st[l]))</span><br><span class="line">    #可能的分割阈值点，!=是因为把取值相同的类分成不同的类没有意义</span><br><span class="line">##    possible=[]</span><br><span class="line">##    for i in range(len(lost_star)):</span><br><span class="line">##        if lost_star[i][-1]!=lost_star[i+1][-1]:</span><br><span class="line">##            possible+=[str((int(lost_star[i][l])+int(lost_star[i+1][l]))/2)]</span><br><span class="line">##            print(possible)</span><br><span class="line">    possible=[str((float(gear[i][l])+float(gear[i+1][l]))/2) for i in range(len(gear)-1) if gear[i][-1]!=gear[i+1][-1]]</span><br><span class="line">    scrap=&#123;&#125;</span><br><span class="line">    for j in possible:</span><br><span class="line">        subset1=[gear[i] for i in range(len(gear)) if float(gear[i][l])&lt;float(j)]#小于该分割点的子集</span><br><span class="line">        subset2=[gear[i] for i in range(len(gear)) if float(gear[i][l])&gt;=float(j)]#大于ry</span><br><span class="line">        scrap[j]=len(subset1)/len(lost_star)*entropy(subset1,-1)+len(subset2)/len(lost_star)*entropy(subset2,-1)#计算不同分割点的熵</span><br><span class="line">    threshold=[i for i,j in scrap.items() if j == min(scrap.values())][0]#阈值，增益和熵成反比所以min</span><br><span class="line">    for i in lost_star:</span><br><span class="line">        #解释一下这个学来的操作，大概就相当于[&apos;&gt;=&apos;,&apos;&lt;&apos;][0 or 1]</span><br><span class="line">        #a cool trick, right? :D</span><br><span class="line">        i[l]=[&apos;&gt;=&apos;,&apos;&lt;&apos;][float(i[l])&gt;=float(threshold)]+threshold</span><br><span class="line">    return lost_star</span><br><span class="line">    </span><br><span class="line">def entropy(lost_star,l):#计算信息熵  参数：数据集,列数</span><br><span class="line">    star=&#123;&#125;</span><br><span class="line">    entropy=0</span><br><span class="line">    for i in range(len(lost_star)):</span><br><span class="line">        if lost_star[i][l] not in star.keys(): #一个字典</span><br><span class="line">            star[lost_star[i][l]]=0#key:value = 结果取值:个数</span><br><span class="line">        star[lost_star[i][l]]+=1</span><br><span class="line">    for i in star.values():</span><br><span class="line">        entropy += -(i/sum(star.values()))*log(i/sum(star.values()),2)#熵，∑-p*log2(p)</span><br><span class="line">    return entropy</span><br><span class="line"></span><br><span class="line">def gainratio(en,e,j,lost_star):#信息增益率 参数：结果熵,属性熵,列数,数据集</span><br><span class="line">    if e == 0:</span><br><span class="line">        return 0</span><br><span class="line">    entropy_info=0 #属性∑，即∑|Dv|/D * Entropy(playgolf? in Dv)</span><br><span class="line">    a_value=set([lost_star[i][j] for i in range(len(lost_star))])#属性可能的取值</span><br><span class="line">    for i in a_value:</span><br><span class="line">        subset=get_subset(lost_star,i,j)#得到属性取值对应子集</span><br><span class="line">        entropy_info += len(subset)/len(lost_star)*entropy(subset,len(subset[0])-1)#属性∑ = 取值权重*子集熵</span><br><span class="line">    return (en - entropy_info)/e    #（结果熵-属性∑）/属性熵 = gainratio</span><br><span class="line"></span><br><span class="line">def gotcha(lost_star,attributes,en):#生成树  参数：数据集，属性，结果熵</span><br><span class="line">    if en == 0:</span><br><span class="line">        return lost_star[0][-1]</span><br><span class="line">    if len(lost_star[0])==2:</span><br><span class="line">        for i in range(len(lost_star)):</span><br><span class="line">            if lost_star[i][-1] not in star:</span><br><span class="line">                star[lost_star[i][-1]]=0</span><br><span class="line">            star[lost_star[i][-1]]+=1</span><br><span class="line">        for i,j in lost_star.items():</span><br><span class="line">            if j == max(lost_star.values()):</span><br><span class="line">                return i</span><br><span class="line">    #↑如果结果熵是0（结果唯一）或属性只剩一个</span><br><span class="line">    dust=&#123;&#125;</span><br><span class="line">    for i in range(len(attributes)):</span><br><span class="line">        dust[attributes[i]]=gainratio(en,entropy(lost_star,i),i,lost_star)#属性对应信息增益率</span><br><span class="line">    #↓试图压缩行数，写了个智熄操作搞到节点</span><br><span class="line">    branch=[i for i,j in dust.items() if j == max(dust.values())][0]</span><br><span class="line">    num=attributes.index(branch)#得到被选作节点的属性所在列数</span><br><span class="line">    del(attributes[num])        #把该属性从属性列表中删除</span><br><span class="line">    b_value=set([lost_star[i][num] for i in range(len(lost_star))])#被选作节点的属性可能的取值</span><br><span class="line">    tree=&#123;branch:&#123;&#125;&#125;</span><br><span class="line">    #写个循环调get_subset拿到属性不同取值对应的子集然后递归</span><br><span class="line">    for i in b_value:</span><br><span class="line">        subset=get_subset(lost_star,i,num)</span><br><span class="line">        for a in range(len(subset)):</span><br><span class="line">            subset[a].remove(subset[a][num])#去除被选作节点的属性</span><br><span class="line">        entro=entropy(subset,len(subset[0])-1)#子集的结果熵</span><br><span class="line">        subattributes = attributes[:]#化腐朽为神奇.jpg 如果不备份直接传会炸</span><br><span class="line">        tree[branch][i]=gotcha(subset,subattributes,entro)#拿到下一个节点ry</span><br><span class="line">    return tree</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    path = r&apos;data.txt&apos;</span><br><span class="line">    with open(path) as f:</span><br><span class="line">        data = f.readlines()</span><br><span class="line"></span><br><span class="line">    attributes,lost_star,en = stardust(data)#拿到属性，具体数据集和结果熵</span><br><span class="line">    tree=gotcha(lost_star,attributes,en)</span><br><span class="line">    print(tree)</span><br></pre></td></tr></table></figure><p>图像代码（复制来的）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: cp936 -*-  </span><br><span class="line">import matplotlib.pyplot as plt  </span><br><span class="line">from kadoya import *  #c4.5算法的py文件名</span><br><span class="line">decisionNode = dict(boxstyle = &apos;sawtooth&apos;, fc = &apos;0.8&apos;)  </span><br><span class="line">leafNode = dict(boxstyle = &apos;round4&apos;, fc = &apos;0.8&apos;)  </span><br><span class="line">arrow_args = dict(arrowstyle = &apos;&lt;-&apos;)  </span><br><span class="line">  </span><br><span class="line">def plotNode(nodeTxt, centerPt, parentPt, nodeType):  </span><br><span class="line">    createPlot.ax1.annotate(nodeTxt, xy = parentPt, xycoords = &apos;axes fraction&apos;,xytext = centerPt, textcoords = &apos;axes fraction&apos;,va = &apos;center&apos;, ha = &apos;center&apos;, bbox = nodeType, arrowprops = arrow_args)  </span><br><span class="line">  </span><br><span class="line"># 使用文本注解绘制树节点  </span><br><span class="line">def createPlot():  </span><br><span class="line">    fig = plt.figure(1, facecolor = &apos;white&apos;)  </span><br><span class="line">    fig.clf()  </span><br><span class="line">    createPlot.ax1 = plt.subplot(111, frameon = False)  </span><br><span class="line">    plotNode(&apos;a decision node&apos;, (0.5,0.1), (0.1,0.5), decisionNode)  </span><br><span class="line">    plotNode(&apos;a leaf node&apos;, (0.8, 0.1), (0.3,0.8), leafNode)  </span><br><span class="line">    plt.show()  </span><br><span class="line">  </span><br><span class="line">#获取叶子节点数目和树的层数  </span><br><span class="line">def getNumLeafs(myTree):  </span><br><span class="line">    numLeafs = 0  </span><br><span class="line">    #firstStr = myTree.keys()[0]</span><br><span class="line">    firstSides = list(myTree.keys())</span><br><span class="line">    firstStr = firstSides[0]</span><br><span class="line">    secondDict = myTree[firstStr]  </span><br><span class="line">    for key in secondDict.keys():  </span><br><span class="line">        if(type(secondDict[key]).__name__ == &apos;dict&apos;):  </span><br><span class="line">            numLeafs += getNumLeafs(secondDict[key])  </span><br><span class="line">        else: numLeafs += 1  </span><br><span class="line">    return numLeafs  </span><br><span class="line">  </span><br><span class="line">def getTreeDepth(myTree):  </span><br><span class="line">    maxDepth = 0  </span><br><span class="line">    #firstStr = myTree.keys()[0]</span><br><span class="line">    firstSides = list(myTree.keys())</span><br><span class="line">    firstStr = firstSides[0]</span><br><span class="line">    secondDict = myTree[firstStr]  </span><br><span class="line">    for key in secondDict.keys():  </span><br><span class="line">        if(type(secondDict[key]).__name__ == &apos;dict&apos;):  </span><br><span class="line">            thisDepth = 1+ getTreeDepth(secondDict[key])  </span><br><span class="line">        else: thisDepth = 1  </span><br><span class="line">        if thisDepth &gt; maxDepth: maxDepth = thisDepth  </span><br><span class="line">    return maxDepth  </span><br><span class="line">  </span><br><span class="line">#更新createPlot代码以得到整棵树  </span><br><span class="line">def plotMidText(cntrPt, parentPt, txtString):  </span><br><span class="line">    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]  </span><br><span class="line">    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]  </span><br><span class="line">    createPlot.ax1.text(xMid, yMid, txtString, va=&quot;center&quot;, ha=&quot;center&quot;, rotation=30)  </span><br><span class="line">  </span><br><span class="line">def plotTree(myTree, parentPt, nodeTxt):#if the first key tells you what feat was split on  </span><br><span class="line">    numLeafs = getNumLeafs(myTree)  #this determines the x width of this tree  </span><br><span class="line">    depth = getTreeDepth(myTree)  </span><br><span class="line">    #firstStr = myTree.keys()[0]     #the text label for this node should be this</span><br><span class="line">    firstSides = list(myTree.keys())</span><br><span class="line">    firstStr = firstSides[0]</span><br><span class="line">    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff)  </span><br><span class="line">    plotMidText(cntrPt, parentPt, nodeTxt)  </span><br><span class="line">    plotNode(firstStr, cntrPt, parentPt, decisionNode)  </span><br><span class="line">    secondDict = myTree[firstStr]  </span><br><span class="line">    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD  </span><br><span class="line">    for key in secondDict.keys():  </span><br><span class="line">        if type(secondDict[key]).__name__==&apos;dict&apos;:#test to see if the nodes are dictonaires, if not they are leaf nodes     </span><br><span class="line">            plotTree(secondDict[key],cntrPt,str(key))        #recursion  </span><br><span class="line">        else:   #it&apos;s a leaf node print the leaf node  </span><br><span class="line">            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW  </span><br><span class="line">            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)  </span><br><span class="line">            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))  </span><br><span class="line">    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD  </span><br><span class="line">#if you do get a dictonary you know it&apos;s a tree, and the first element will be another dict  </span><br><span class="line">  </span><br><span class="line">def createPlot(inTree):  </span><br><span class="line">    fig = plt.figure(1, facecolor=&apos;white&apos;)  </span><br><span class="line">    fig.clf()  </span><br><span class="line">    axprops = dict(xticks=[], yticks=[])  </span><br><span class="line">    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)    #no ticks  </span><br><span class="line">    #createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses   </span><br><span class="line">    plotTree.totalW = float(getNumLeafs(inTree))  </span><br><span class="line">    plotTree.totalD = float(getTreeDepth(inTree))  </span><br><span class="line">    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0;  </span><br><span class="line">    plotTree(inTree, (0.5,1.0), &apos;&apos;)  </span><br><span class="line">    plt.show() </span><br><span class="line"></span><br><span class="line">path = r&apos;data.txt&apos;</span><br><span class="line">with open(path) as f:</span><br><span class="line">    data = f.readlines()</span><br><span class="line">attributes,lost_star,en = stardust(data)#拿到具体数据集和结果熵</span><br><span class="line">tree=gotcha(lost_star,attributes,en)</span><br><span class="line">print(tree)</span><br><span class="line">createPlot(tree)</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
